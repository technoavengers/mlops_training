{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started With ML Project With MLFLOW\n",
    "\n",
    "- Installing MLflow.\n",
    "\n",
    "- Starting a local MLflow Tracking Server.\n",
    "\n",
    "- Logging and registering a model with MLflow.\n",
    "\n",
    "- Loading a logged model for inference using MLflow‚Äôs pyfunc flavor.\n",
    "\n",
    "- Viewing the experiment results in the MLflow UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Local MLflow Tracking Server\n",
    "\n",
    "1. Open Terminal.\n",
    "\n",
    "2. Run the below command to start MLflow on localhost on port `5001`:\n",
    "   ```bash\n",
    "   python -m mlflow server --host 127.0.0.1 --port 5001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Access MLFlow Server\n",
    "\n",
    "Open your browser and access the MLflow server at the following link:\n",
    "\n",
    "   http://127.0.0.1:5001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and preprocess the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Walmart.csv' \n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'transaction_date' to datetime and extract features\n",
    "dataset['transaction_date'] = pd.to_datetime(dataset['transaction_date'], errors='coerce')\n",
    "dataset['transaction_day'] = dataset['transaction_date'].dt.day\n",
    "dataset['transaction_month'] = dataset['transaction_date'].dt.month\n",
    "dataset['transaction_weekday'] = dataset['transaction_date'].dt.weekday\n",
    "dataset['transaction_year'] = dataset['transaction_date'].dt.year\n",
    "dataset = dataset.drop(columns=['transaction_date'])\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['category', 'store_location', 'payment_method', 'promotion_applied', \n",
    "                       'promotion_type', 'weather_conditions', 'holiday_indicator', 'weekday', \n",
    "                       'customer_loyalty_level', 'customer_gender']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    dataset[col] = encoder.fit_transform(dataset[col].astype(str))\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = dataset.drop(columns=['transaction_id', 'customer_id', 'product_id', 'product_name', 'actual_demand'])\n",
    "y = dataset['actual_demand']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walmart Demand Forecasting model is trained\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define hyperparameters for the model\n",
    "params = {\n",
    "    \"n_estimators\": 100,       # Number of trees\n",
    "    \"max_depth\": None,         # No maximum depth\n",
    "    \"min_samples_split\": 2,    # Minimum samples required to split an internal node\n",
    "    \"min_samples_leaf\": 1,     # Minimum samples required to be a leaf node\n",
    "    \"random_state\": 42         # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize and train the Random Forest Regressor\n",
    "model = RandomForestRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Walmart Demand Forecasting model is trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 107.17233\n",
      "R2 Score: -0.03293575634425849\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Output the results\n",
    "print(f\"Mean Absolute Error: {mae}\")\n",
    "print(f\"R2 Score: {r2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Track the experiment with MLFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/01/14 16:50:05 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üèÉ View run bedecked-gull-604 at: http://127.0.0.1:5001/#/experiments/304321649578051944/runs/c8ba87d4c0614c7999faebfc85c3de88\n",
      "üß™ View experiment at: http://127.0.0.1:5001/#/experiments/304321649578051944\n"
     ]
    }
   ],
   "source": [
    "### MLFLOW tracking\n",
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5001\")\n",
    "mlflow.set_experiment(\"Walmart Demand Forecast Model Experiment\")\n",
    "\n",
    "# Start an MLflow run\n",
    "with mlflow.start_run():\n",
    "\n",
    "    # Log parameters, metrics, and the model\n",
    "    mlflow.log_params(params)\n",
    "    mlflow.log_metric(\"mean absolute error\", mae)\n",
    "    mlflow.log_metric(\"r2 Score\", r2)\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_regressor_model\")\n",
    "\n",
    "# End MLflow run\n",
    "mlflow.end_run()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain the model with different params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titanic Prediction Model is trained\n"
     ]
    }
   ],
   "source": [
    "# Define hyperparameters for the model\n",
    "params = {\n",
    "    \"n_estimators\": 150,       # Number of trees\n",
    "    \"max_depth\": 5,         # No maximum depth\n",
    "    \"min_samples_split\": 2,    # Minimum samples required to split an internal node\n",
    "    \"min_samples_leaf\": 1,     # Minimum samples required to be a leaf node\n",
    "    \"random_state\": 42         # Random seed for reproducibility\n",
    "}\n",
    "\n",
    "# Initialize and train the Random Forest Regressor\n",
    "model = RandomForestRegressor(**params)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Walmart Demand Forecasting model is Re-trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "file_path = 'Walmart_validation.csv' \n",
    "dataset = pd.read_csv(file_path)\n",
    "\n",
    "# Convert 'transaction_date' to datetime and extract features\n",
    "dataset['transaction_date'] = pd.to_datetime(dataset['transaction_date'], errors='coerce')\n",
    "dataset['transaction_day'] = dataset['transaction_date'].dt.day\n",
    "dataset['transaction_month'] = dataset['transaction_date'].dt.month\n",
    "dataset['transaction_weekday'] = dataset['transaction_date'].dt.weekday\n",
    "dataset['transaction_year'] = dataset['transaction_date'].dt.year\n",
    "dataset = dataset.drop(columns=['transaction_date'])\n",
    "\n",
    "# Encode categorical variables\n",
    "categorical_columns = ['category', 'store_location', 'payment_method', 'promotion_applied', \n",
    "                       'promotion_type', 'weather_conditions', 'holiday_indicator', 'weekday', \n",
    "                       'customer_loyalty_level', 'customer_gender']\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_columns:\n",
    "    dataset[col] = encoder.fit_transform(dataset[col].astype(str))\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "X = dataset.drop(columns=['transaction_id', 'customer_id', 'product_id', 'product_name', 'actual_demand'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227.43 405.39 372.31 378.35 388.77 282.41 267.1  275.21 267.35]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "logged_model = 'runs:/c8ba87d4c0614c7999faebfc85c3de88/random_forest_regressor_model'\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on validation data\n",
    "predictions = loaded_model.predict(X)\n",
    "\n",
    "# Display predictions\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Access Registered Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[227.43 405.39 372.31 378.35 388.77 282.41 267.1  275.21 267.35]\n"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model_name=\"Walmart_Demand_Forecast\"\n",
    "model_version=\"latest\"\n",
    "model_uri = f'models:/{model_name}/{model_version}'\n",
    "loaded_model = mlflow.pyfunc.load_model(logged_model)\n",
    "\n",
    "# Predict on validation data\n",
    "predictions = loaded_model.predict(X)\n",
    "\n",
    "# Display predictions\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
